% https://www.monash.edu/graduate-research/examination/publication
% https://www.monash.edu/rlo/graduate-research-writing/write-the-thesis
% https://www.monash.edu/rlo/graduate-research-writing/write-the-thesis/writing-the-thesis-chapters/structuring-a-long-text
\abstract{
\addtocontents{toc}{}  % Add a gap in the Contents, for aesthetics

In dynamic environments, a goal of Artificial Intelligence (AI)
is to build intelligent agents capable of addressing
sequential decision-making settings.
%
In this context, there are two important challenges for
humans to understand decisions made by agents:
%
(1) the sequential decisions are connected,
%
(2) the environment can play a role in the outcome
%
and (3) the agents may use opaque black-box models
for each decision.

Despite the success of 
AI in sequential decision-making (e.g. Reinforcement Learning),
%
the lack of transparency in understanding their decisions
can make the agents hard to validate.
%
To address the need for transparency, there are
efforts to develop Explainable Artificial Intelligence (XAI).
%
XAI is a set of methods designed to make AI models easier
to comprehend.
%
Despite the importance of Explainable Reinforcement
Learning in developing trustworthy intelligent agents,
%
there are gaps in current research to make sequential
decision-making explainable.

This project proposes to explain sequential
decision-making using formal reasoning.
To achieve this goal, the proposal focuses on
%
(1) Formal Explainability for Finite Automata,
to address sequential actions in deterministic
environments, 
%
(2) Formal Explainability for Pushdown Automata,
to address sequential actions with stack-based memory,
%
and (3) Formal Explainability for
stochastic models, where outcomes
are subject to environmental uncertainty.

}
