\chapter{Progress}

\section{Model Proposal: Context-Free Grammar (CFG) Explanations}

The research has evolved
from the study of Finite Automata (FA)
to more expressive computational models.
%
While FA provided a baseline for explaining
sequential behaviors,
%
many complex problems require the model to
``remember'' an arbitrary number of previous
inputs in the sequence
to determine the validity of subsequent inputs

Consider the abstract language $L=\{a^{n}b^{n} \mid n \geq 1\}$,
which represents a sequence where every `a' must
be matched by a corresponding `b'.

\begin{itemize}
  %
  \item The Limitation: A standard
  Finite Automaton (FA) possesses no
  auxiliary memory.
  %
  Therefore, it cannot count the number
  of $a$'s to ensure they match the number
  of $b$'s once $n$ exceeds the number
  of states in the machine.
  \item The Explanation Failure:
  If an FA were used to validate such a sequence,
  it would process inputs locally.
  %
  Upon encountering a mismatch (e.g., $a^{4}b^{2}$),
  it might reject the sequence, but it lacks the
  structural context to generate a contrastive
  explanation such as:
  "The sequence is invalid because the third or fourth `a'
  was not closed by a matching `b'."
  Instead, it can only report a
  "transition failure" at the specific index,
  obscuring the root cause of the error.

\end{itemize}

\begin{itemize}
  \item \textbf{From FA to PDA:}
  We propose the use of Pushdown Automata (PDAs)
  to model decision-making processes with memory.

  Unlike FA, the addition of a stack
  allows the description of more complex
  languages.
  Here the challenge is how to explain
  PDA decisions.
\end{itemize}

\section{Motivation: The Gap between Detection and Explanation}

One well established applications of Context-Free Grammars
is in the design of programming languages and compilers.
Compilers are highly efficient at detecting when a
sequence of tokens fails to belong to a grammar.
%
However, a fundamental question is:
are they able of generating a useful \emph{explanation}
for why the failure occurred or how to fix it?

Consider the following C code, where a typo has
introduced a double opening bracket \texttt{\{\{} in the \texttt{for} loop:
%
\begin{lstlisting}[language=C]
int main(){
    for(int i=0; i<10; i++){{  // <--- Error: Double bracket
        printf("hello");
    }
}
\end{lstlisting}
%
When compiled (e.g., using GCC or Clang), the parser
consumes the input until it reaches
\textless\textless EOF\textgreater\textgreater (end-of-file),
finding only then that
EOF was not expected,
instead there is an incomplete structure, the token `\}'
is expected before \textless\textless EOF\textgreater\textgreater.
The resulting error message is:
%
\begin{verbatim}
error: expected '}' at end of input
   5 | }
     |  ^
\end{verbatim}
%
\noindent \textbf{The Explanation:}
While the compiler's output is correct,
the file ended while the stack still
contained an open brace that was not closed yet.
It is \textit{misleading}.
\begin{itemize}
  %
  \item \textbf{Root Cause:}
  The compiler points to line 5
  (the end of the file) as the location of the error.
  However, the root cause is located at line 2.
  %
  \item \textbf{Lack of Contrastive Reasoning:}
  A human (or a formal explainer) would identify
  that the input is ``almost correct''.
  %
  The explanation should not just report a
  missing symbol at the end,
  but rather propose a \textit{minimal correction}.
  %
\end{itemize}
%
In this case, the minimal correction is not to add a brace at the end,
but to remove the redundant opening brace at the loop initialization:
%
\begin{lstlisting}[language=C]
int main(){
    for(int i=0; i<10; i++){
        printf("hello");
    }
}
\end{lstlisting}
%
This discrepancy motivates the need for our proposed formal framework.
We aim to move beyond isolated decisions to
eplained decisions revealing
these minimal set of edits (Contrastive Explanations).

\section{Preliminaries} 

\subsection{Pushdown Automata and Context-Free Grammars}

To provide a foundation for the proposed explanation
extraction methods, 
standard definitions and notations
for Pushdown Automata and Context-Free Grammar are adopted
\cite{IntroAutomataTheory,HandbookTheoreticalContextFreeGrammar}.

\begin{definition}[Pushdown Automaton]
  A Pushdown Automaton (PDA) extends the capabilities of a
  Finite Automaton by incorporating an infinite memory stack.
  A PDA is formally defined as a 7-tuple
  $\mathcal{A}=(Q,\Sigma,V,\delta,q^0,v^0,F)$, where:
  \begin{itemize}
    %
    \item Q is a finite set of states.
    %
    \item $\Sigma$ is the input alphabet, a finite
    terminal alphabet.
    %
    \item $V$ is the stack alphabet, a finite
    nonterminal alphabet that can be pushed
    onto or popped from the stack.
    %
    \item $\delta:Q\times(\Sigma\cup\{\epsilon\}) \times V \rightarrow \mathcal{P}(Q \times V^*)$
    %
    \footnote{$\mathcal{P}$ denotes the power set
    (the set of all its subsets).
    %
    $V^*$ and $\Sigma^*$ denote the Kleene closures
    of the stack and input alphabets,
    respectively,
    %
    representing the sets of all finite strings formed
    by those alphabets.}
    %
    is the transition fuction.
    %
    It dictates how the machine transitions between states and
    modifies the stack based on the current state, input symbol,
    and the top symbol of the stack.
    %
    \item $q^0 \in Q$ is the initial state.
    \item $v^0 \in V$ is the initial pushdownstore symbol.
    \item $F\subseteq Q$ is the set of accepting states.
  \end{itemize}
%
  A configuration of $\mathcal{A}$ is a triple $c=(q, \gamma, x)$ in
  $Q\times V^*\times\Sigma^*$. And the automaton moves from c into configuration
  $c'=(q',\gamma', x')$, denoted as $c\vdash c'$ if:
  %
  \begin{itemize}
    %
    \item $\gamma = v \gamma_1(v\in V)$
    %
    \footnote{$\gamma_{1} \in V^*$ represents
    the remaining symbols on the
    stack below the top symbol $v$.
    %
    Thus, $\gamma$ represents the full current stack, formed by
    the top symbol $v$ (to be processed) and the rest of the stack $\gamma_1$.}
    %
    , $x=ax' (a\in \Sigma)$,
    $\gamma'= m \gamma_1(m\in V^*)$ and $(q', m)\in \delta(q, a, v)$, namely ``a-move'';
    %
    \item or $\gamma = v \gamma_1(v\in V)$, $x=x'$, $\gamma'= m \gamma_1(m\in V^*)$
    and $(q',m)\in \delta(q,\epsilon,v)$, namely ``$\epsilon$-move''.
  \end{itemize}
  %
  A \emph{word} is accepted by a pushdown automaton if, starting with an
  empty stack, there is a path through the automaton such
  that the automaton stops in an
  accepting state after the entire string has been read.
  %
  The \emph{language} recognized by a PDA $\mathcal{A}$
  is the set of all accepted words, denoted as $L(\mathcal{A})$.
  %
\end{definition}

The following PDA recognizes the
language of balanced parentheses
(a subset of the Dyck language)
%
\footnote{
  The Dyck language describes a set of strings
  with balanced and properly
  nested brackets (e.g., (), [], \{\})
  %
  \cite{HandbookTheoreticalContextFreeGrammar}.
  The example focuses solely on non-empty
  sequences of balanced ( and ).
}
%
and is used throughout the document
to illustrate the proposed ideas.
%

\begin{figure}[h]
  \centering
    \input{Figures/PDA/parenthesis_PDA.tex}
    \caption{A Pushdown Automaton $\mathcal{A}$
    accepting the language of balanced parentheses.
    The symbol \$ is used as the bottom-of-stack marker.}
  \label{fig:pda_example}
\end{figure}

\begin{example}

  Let $\mathcal{A}$ be the PDA
  that accepts the language generated by $G$ in 
  \autoref{ex:grammar_balanced}.
  The PDA uses a stack to track the depth of nesting,
  pushing a symbol for every open parenthesis and popping
  for every closed one. $B$ represents \textit{Balanced} in $G$.
  
  \begin{itemize}
      \item States: $Q = \{q_0, q_1, q_f\}$, $q^0=q_0$, $F=\{q_f\}$
      \item Input Alphabet: $\Sigma = \{(,)\}$
      \item Stack Alphabet: $V = \{ (, ), B, \$ \}$, $v^0=B$
      \item Transitions:
      \begin{enumerate}
          \item $\delta(q_0, \epsilon, \epsilon) = \{(q_1, B\,\$)\}$ \quad (Initialize stack with Start Symbol)
          \item $\delta(q_1, \epsilon, B) = \{(q_1, (B)B),(q_1, (B)),(q_1, ()B),(q_1, ())\}$ \quad (Expand $B$)
          \item $\delta(q_1, (, () = \{(q_1, \epsilon)\}$ \quad (Match input `(' with stack `(')
          \item $\delta(q_1, ), )) = \{(q_1, \epsilon)\}$ \quad (Match input `)' with stack `)')
          \item $\delta(q_1, \epsilon, \$) = \{(q_f, \epsilon)\}$ \quad (Accept if bottom marker is reached)
      \end{enumerate}
  \end{itemize}

  \autoref{fig:pda_example} illustrates this PDA.
  The configuration history of $\mathcal{A}$ for the input ``()()'' is:
%
  \begin{equation}
    \begin{aligned}
        & (q_0, \text{()()}, \epsilon) \\
        \vdash \ & (q_1, \text{()()}, B\$) && \text{(Initialize)} \\
        \vdash \ & (q_1, \text{()()}, ()B\$) && \text{(Expand } B \to ()B \text{)} \\
        \vdash \ & (q_1, \text{)()}, )B\$) && \text{(Match `(')} \\
        \vdash \ & (q_1, \text{()}, B\$) && \text{(Match `)')} \\
        \vdash \ & (q_1, \text{()}, ()\$) && \text{(Expand } B \to () \text{)} \\
        \vdash \ & (q_1, \text{)}, )\$) && \text{(Match `(')} \\
        \vdash \ & (q_1, \epsilon, \$) && \text{(Match `)')} \\
        \vdash \ & (q_{f}, \epsilon, \epsilon) && \text{(Accept)}
    \end{aligned}
  \end{equation}
\end{example}

\begin{definition}[Context-Free Grammar]
  A Context-Free Grammar (CFG)
  is defined as a 4-tuple $G=(V,\Sigma ,R,S)$, where:
  \begin{itemize}
    \item V (Variables/Non-terminals) is a finite set of variables (non-terminal symbols).
    \item $\Sigma$ (Terminals) is a finite set of terminal symbols, disjoint from V.
    \item R is a finite set of production rules of the
    form $A \rightarrow \alpha$, where $A\in V$ describes
    a variable and $\alpha\in(V \cup\Sigma)^*$ is a string
    of variables and terminals.
    \item $S\in V$ is the start variable.
  \end{itemize}
\end{definition}
%

A fundamental equivalence between CFGs and PDAs:
a language $L$ is context-free iff there exists a
PDA $\mathcal{A}$ such that $L(\mathcal{A})=L$
\cite{HandbookTheoreticalContextFreeGrammar, IntroAutomataTheory}.
%
This equivalence allows us to use grammar-based
parsing algorithms, such as CYK, to analyze the
behavior of PDAs.

\begin{example}
  \label{ex:grammar_balanced}
  Let $G=(\{Balanced\}, \{(,)\}, R, Balanced)$ be the grammar
  defined by the following 
  production rules $R$:
  %
  \begin{equation}
  \begin{aligned}
      Balanced &\to ( \, Balanced \, ) \, Balanced & \text{(Rule 1)}\\
      Balanced &\to ( \, Balanced \, ) & \text{(Rule 2)}\\
      Balanced &\to ( \, ) \, Balanced & \text{(Rule 3)}\\
      Balanced &\to ( \, ) & \text{(Rule 4)}
  \end{aligned}
  \end{equation}
  %
  This grammar generates the language of
  properly nested parentheses.
  For instance, the string ``()()''
  can be derivated as follows.
  %
  \begin{equation}
  \begin{aligned}
      Balanced &\Rightarrow ( \, ) \, \mathbf{Balanced}  && \text{(Rule 3: parentheses and Balanced)} \\
               &\Rightarrow ( \, ) \, ( \, ) && \text{(Rule 4: Reduce `Balanced' to `()')}
  \end{aligned}
  \end{equation}
\end{example}

To analyze the behavior of the PDA
using grammar-based approaches, we must first standardize
the grammar structure (e.g. Chomsky Normal Form).
%
This enables the use of efficient
parsing algorithms 
like CYK (Cocke-Younger-Kasami) \cite{CYK1967, ParsingGuide}.

\subsection{Chomsky Normal Form}

Parsing algorithms often require the grammar to be in a
canonical form to ensure predictable execution complexity.

\begin{definition}[Chomsky Normal Form]
  A Context-Free Grammar $G=(V, \Sigma, R, S)$ is in
  \textit{Chomsky Normal Form} (CNF) \cite{IntroAutomataTheory} if every production rule
  in $R$ is of one of the following two forms:
  \begin{itemize}
      \item $A \rightarrow BC$ (where $A, B, C \in V$)
      \item $A \rightarrow a$ (where $a \in \Sigma$ and $a \neq \epsilon$)
  \end{itemize}
\end{definition}

For every CFG $G$ whose languge contains at least one string
other than $\epsilon$, then there is a grammar $G_1$
in Chomsky Normal Form.

\begin{example}
  \label{ex:cnf_conversion}
  Consider the grammar $G$ from \autoref{ex:grammar_balanced}.
  We transform $G$ into an
  equivalent grammar $G'=(V', \Sigma, R', S)$ in CNF.
  
  \noindent \textbf{Step 1: Terminals to Non-terminals.}
  To introduce variables $L$ and $R$ for terminals `(' and `)'.
  \[ L \to ( \quad \text{and} \quad R \to ) \]
  
  \noindent \textbf{Step 2: Binary decomposition.}
  To rewrite the original rules using new variables
  and break down productions into binary steps.
  
  The resulting production rules $R'$ are:
  \begin{center}
  \begin{tabular}{r r l l}
    Balanced  &$\to$&$ Nested\,Balanced$ & (Represents `( Balanced ) Balanced' ) \\
              &$\mid$& $Unclosed\,R$ & (Represents `( Balanced )' ) \\
              &$\mid$& $Pair\,Balanced$ & (Represents `( ) Balanced' ) \\
              &$\mid$& $L\,R$ & (Represents `( )' ) \\
    Nested &$\to$& $Unclosed\,R$ \\
    Unclosed &$\to$& $L\,Balanced$  \\
    Pair &$\to$& $L\,R$ \\
    L &$\to$& ( \\
    R &$\to$& )
  \end{tabular}
  \end{center}
\end{example}

\subsection{The CYK Algorithm}

The Cocke-Younger-Kasami (CYK) \cite{CYK1967, ParsingGuide}
algorithm is a bottom-up
parsing method that given a CFG $G$ in CNF
determines whether a string $w$ belongs
to a language $L(G)$. It operates via
dynamic programming,
constructing a triangular table
where each cell $T[i,j]$ contains the set of
non-terminals that can generate
the substring of $w$ starting at $i$ and ending at $j$.

\begin{definition}[CYK Table Construction]
  For an input string $w = w_1 w_2 \dots w_n$:
  \begin{enumerate}
      \item \textbf{Base Case:} For each $i \in \{1, \dots, n\}$,
      $T[i,i]$ contains $A$ if there is a rule $A \to w_i$.
      \item \textbf{Recursive Step ($j > i$):}
      $T[i,j]$ contains $A$ if there exists
      a rule $A \to BC$ and a split point $k$ ($i \le k < j$)
      such that $B \in T[i,k]$ and $C \in T[k+1, j]$.
  \end{enumerate}
  The string is accepted if starting symbol $S \in T[1,n]$.
\end{definition}

\begin{example}
  The \autoref{tab:cyk_triangular} illustrates a 
  CYK Table construction to 
  verify the acceptance of the string $w = \text{``()()"}$
  using the CNF grammar derived in \autoref{ex:cnf_conversion}.
  %
  The top-right cell $T[1,4]$ represents the 
  entire string
  %
  It contains the Start symbol $B$ (Balanced)
  because there is a rule `$Balanced \to Pair\,Balanced$'
  for a split point $k=2$ where $Pair\in T[1,2]$ and $Balanced\in T[3,4]$.
  
  Similarly, the cell $T[1,2]$ contains $P$ (Pair) because
  there is a rule $Pair \to L\, R$
  for a split point $k=1$ ($L\in T[1,1]$ and $R\in T[2,2]$).

  \begin{table}[h]
    \centering
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular}{|c|c|c|c|}
    \hline
    $w_1=`('\,\{L\}$ & $\{B,P\}$ & $\emptyset$ & $\mathbf{\{B\}}$ \\ \cline{1-4}

    \multicolumn{1}{c|}{} & $w_2=`)'$ \{R\} & $\emptyset$ & $\emptyset$ \\ \cline{2-4}

    \multicolumn{1}{c}{} & \multicolumn{1}{c|}{} & $w_3=`('$ \{L\} & \{B,P\} \\ \cline{3-4}

    \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c|}{} & $w_4=`)'$ \{R\} \\ \cline{4-4}

    \end{tabular}
    \caption{CYK Table for $w=\text{()()}$. 
    The cells $T[i,j]$ correspond to the substring starting at $i$ and ending at $j$.
    The diagonal elements contain the input terminals and unary rules able to generate them.
    \textbf{Abbreviations:} $B$ = Balanced, $P$ = Pair}
    \label{tab:cyk_triangular}
  \end{table}
\end{example}

