\section{Responsibility Attribution for Token Substitutions}

The linear system treats the probability of a CXP as a
shared resource among its constituent indices.
For each index $i$, the "Responsibility Score" $S_i$ is:
%
$$S_i = \sum_{j: i \in cxp_j} \frac{P(cxp_j)}{|cxp_j|}$$
%
Where $|cxp_j|$ is the size of the explanation (minimal set). 
This accounts for the fact that if an explanation requires
changing 5 tokens, the credit for that fix is
diluted across those 5 letters

\section{Badness Attribution}



Para justificar el uso de la multiplicación en tu modelo de
Rejection Attribution Score (RAS) y su relación con la "maldad"
($v_i$) en el contexto de tu doctorado, debes fundamentarlo en
tres pilares: la lógica booleana de los autómatas, la teoría de
probabilidad de las gramáticas (PCFG) y la tratabilidad matemática.
Aquí tienes la justificación técnica y académica:1. 
La lógica del "Y" (Intersección de Eventos)En la teoría de
lenguajes formales, para que una palabra sea aceptada por un
autómata (o generada por una gramática), todas las restricciones
estructurales deben cumplirse simultáneamente.
Es una condición de tipo AND.Si definimos $(1 - v_i)$ como la
probabilidad de que el índice $i$ sea "correcto" o "válido" según
las reglas de la gramática, la aceptación de la palabra completa
es el evento donde el índice 1 es válido Y el índice 2 es válido
Y así sucesivamente.En teoría de probabilidad, la probabilidad de
la intersección de eventos independientes es el producto de sus
probabilidades individuales: 
$P(\text{Aceptación}) = P(\text{validez}_1) \cdot P(\text{validez}_2) \dots$Por lo tanto, $P = \prod (1 - v_i)$
es la representación natural de una estructura donde el fallo de un
solo componente puede comprometer la aceptación total.



2. Justificación mediante el modelo de "Canal con Ruido"Para tu tesis,
puedes presentar la palabra rechazada como una versión "ruidosa" o "corrupta"
de una palabra válida.Justificación: Cada $v_i$ representa la probabilidad
de que haya ocurrido un error de transformación en el índice $i$.
Bajo esta premisa, la probabilidad de que una palabra reparada
(una explicación contrastiva como $[1, 3]$) sea la "verdadera" intención
del usuario depende de que los demás índices se mantengan correctos.
La multiplicación cuantifica la verosimilitud de esa reparación estructural.