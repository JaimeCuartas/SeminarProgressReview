\section{Formal Explainability}

In this chapter I present some important concepts of 
Formal Explainability that are foundational for this work.
%
Two types of explanations widely used in classification
problems, and a brief illustration of our work developed
during my first year to explain Finite Automata Decisions.

\subsection{Classification Problems and Formal Explanations}

Following XAI literature for classification problems
\cite{delivering_trust,darwiche2023logic}, we consider
a classifier \newline
$\kappa~:~\mathbb{F}\rightarrow \mathcal{K}$
over a feature space $\mathbb{F}=\prod_{i=1}^{m} \mathbb{D}_i$
and a set of classes $\mathcal{K}$.

For an instance $\mathbf{v}\in\mathbb{F}$ with prediction
$\kappa(\mathbf{v})=~c\in~\mathcal{K}$, an
\emph{abductive explanation} 
is a minimal subset of features
$\mathcal{X}\subseteq \{1,\dots , m\}$
\emph{sufficient} for the prediction.
%
Formally, $\mathcal{X}$ is defined as:
%
\begin{equation}
    %
    \label{eq:axp}
    %
    \forall (\textbf{x}\in \mathbb{F}). \left[\bigwedge\nolimits_{i
    \in \mathcal{X}} (x_i=v_i)\right]\rightarrow
    \left(\kappa(\mathbf{x})=c\right)
    %
\end{equation}
%
Similarly, a \emph{contrastive explanation} (CXp) is a
minimal subset of features $\mathcal{Y}\subseteq \{1,\dots , m\}$
that, if allowed to change, enables the prediction's alteration.
%
Formally, a contrastive explanation $\mathcal{Y}$ is defined as follows:
%
\begin{equation}
    %
    \label{eq:cxp}
    %
    \exists (\textbf{x}\in \mathbb{F}). \left[\bigwedge\nolimits_{j
    \not\in \mathcal{Y}} (x_j=v_j)\right] \land
    \left(\kappa(\mathbf{x}) \neq c\right)
    %
\end{equation}
%
Observe that abductive explanations are used to explain \emph{why} a
prediction is made by the classifier $\kappa$ for a given instance, while
contrastive explanations can be seen to answer \emph{why not} another
prediction is made by $\kappa$.
%
Alternatively, CXps can be seen as answering \emph{how} the
prediction can be changed.

Importantly, abductive and contrastive explanations are known to enjoy
a minimal hitting set duality relationship~\cite{axpcxp}.
%
Given $\kappa(\mathbf{v})=~c$, let $\mathbb{A}_\mathbf{v}$ be the
complete set of AXps and $\mathbb{C}_\mathbf{v}$ be the complete set
of CXps for this prediction.
%
Then each AXp $\mathcal{X}\in\mathbb{A}_\mathbf{v}$ is a minimal
hitting set of $\mathbb{C}_\mathbf{v}$ and, vice versa, each CXp
$\mathcal{Y}\in\mathbb{C}_\mathbf{v}$ is a minimal hitting set of
$\mathbb{A}_\mathbf{v}$.\footnote{Given a collection of sets
$\mathbb{S}$, a \emph{hitting set} of $\mathbb{S}$ is a set $H$ such
that for each $S \in \mathbb{S}$, $H \cap S \neq \emptyset$. A
hitting set is \emph{minimal} if no proper subset of it is a
hitting set.}
%
This fact is the basis for the algorithms used for formal explanation
\emph{enumeration}~\cite{delivering_trust,ffa}.

\subsection{Explaining Finite Automata Decisions}

Here, we adopt standard definitions and notations for \emph{finite
automata} and \emph{regular expressions}
\cite{FA_and_their_decision_problems,FA_languages,PERRIN19901}.
%
$\emptyset$ denotes the empty language, $c\in \Sigma$
denotes the language $\{c\}$, 
%
and $\Sigma$ denotes the language containing the
wildcard character
(representing any single character),
the set of all strings of length 1.
%
In general, given a regular expression $R$, the language it defines is
denoted by $L(R)$.
%
The concatenation of two regular expressions $R_1 R_2$ denotes the
regular language $\{ r_1 r_2 \mid r_1 \in L(R_1), r_2 \in L(R_2)\}$.


In this work, we aim to explain the behaviour of a finite automaton
$\mathcal{A}$ on an input $w\in\Sigma^*$, which can be viewed as a
classifier mapping input $w$ to a class in ${\cal K} = \{
\mbox{accept}, \mbox{reject} \}$.
%
Similar to classification problems, we propose two types of
explanations for FA: abductive explanations (AXps) and contrastive
explanations (CXps).
%
Informally, an AXp answers
``Why does $\mathcal{A}$ accept/reject $w$?''
%
while a CXp answers
``How can $w$ be modified to alter the response of $\mathcal{A}$?''.
%

In that work, we introduced a class of explanation
languages based on regular expressions.
%
They are formed by replacing selected characters
in $w$ with $\Sigma$ (representing any character).

\begin{figure}[b]
  \centering
    \input{Figures/fa/fa_example_trace.tex}
    \caption{
      Input \texttt{bbbbb} is accepted by this automaton.
      Opaque states indicate transitions that are not traversed
      for the input \texttt{bbbbb}.
      Two valid explanations are \texttt{\underline{bb}bbb} and
      (a shorter one) \texttt{bb\underline{b}bb}.}
  \label{fig:bbbbb_trace}
\end{figure}

\begin{figure}[b]
  \centering
  \input{Figures/FA/mhs.tex}
  \caption{
    Duality between AXps and CXps in $\Sigma$.
    AXps fix the characters at given indices;
    CXps free them.
  }
  \label{fig:mhs_explanations_dot}
\end{figure}

\begin{example}\label{ex:bbbbb}
  %
  Consider the deterministic FA $\mathcal{A}$
  shown in Figure~\ref{fig:bbbbb_trace}.
  %
  Observe that it accepts the input word \texttt{bbbbb}.
  %
  How should we explain this?
  %
  One obvious way is to trace the execution of the automaton on the
  input word.
  %
  Clearly, reading the first two \texttt{b}'s leads to an accepting
  state, so an explanation could be \texttt{\underline{bb}bbb} 
  ($L(\texttt{bb}\Sigma\Sigma\Sigma) \subseteq L(\mathcal{A})$),
  where the underlined characters are those that explain the acceptance.
  %
  However, other (shorter) explanations exist, e.g.
  \texttt{bb\underline{b}bb} 
  ($L(\Sigma\Sigma\texttt{b}\Sigma\Sigma) \subseteq L(\mathcal{A})$)
  is a correct explanation, as any word of
  length 5 with a \texttt{b} in position 3 will be accepted.
  Once we have one type of explanation, we can easily
  extract the other using Minimal Hitting sets,
  as illustrated in \autoref{fig:mhs_explanations_dot}.
  AXps fix indices while CXps free them, revealing
  a minimal set where it is possible to flip the prediction
  (obtain a rejected word).
  %
  \qed
  %
\end{example}

Formal definitions and more details about this and other
explanation languages can be found in the paper
at the end of this report.